# This workflow will upload a Python Package using Twine when a release is created
# For more information see: https://docs.github.com/en/actions/automating-builds-and-tests/building-and-testing-python#publishing-to-package-registries

# This workflow uses actions that are not certified by GitHub.
# They are provided by a third-party and are governed by
# separate terms of service, privacy policy, and support
# documentation.

name: Upload Python Package

on:
  release:
    types: [published]

permissions:
  contents: read

jobs:
  build:
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v4  
    - name: Edit version
      run: sed -i 's/version = \".*\"/version = \"${{ github.event.release.tag_name }}\"/g' pyproject.toml
    - name: Make the script files executable
      run: chmod +x ./database/build.sh
    - name: Run a script
      working-directory: ./database
      run: ./build.sh
    - name: Move file
      run: mv ./database/pg_deploy.sql ./cli/dataforge/resources/
    - name: Save pgdeploy file
      uses: actions/upload-artifact@v4
      with:
        name: pgdeploy
        path: ./cli/dataforge/resources/pg_deploy.sql
    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.x'
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install build
    - name: Build package
      run: python -m build
    - name: Store the distribution packages
      uses: actions/upload-artifact@v4
      with:
        name: python-package-distributions
        path: dist/

  publish-to-testpypi:
    name: publish python distribution to TestPyPi
    needs:
    - build
    runs-on: ubuntu-latest

    environment:
      name: testpypi
      url: https://test.pypi.org/p/dataforge-core

    permissions:
      id-token: write  # IMPORTANT: mandatory for trusted publishing

    steps:
    - name: Download all the dists
      uses: actions/download-artifact@v4
      with:
        name: python-package-distributions
        path: dist/
    - name: publish dist to TestPyPI
      uses: pypa/gh-action-pypi-publish@release/v1
      with:
        repository-url: https://test.pypi.org/legacy/

  publish-to-prodpypi:
    if: "!github.event.release.prerelease"
    name: publish python distribution to ProdPyPi
    needs:
    - build
    runs-on: ubuntu-latest

    environment:
      name: prodpypi
      url: https://pypi.org/p/dataforge-core

    permissions:
      id-token: write  # IMPORTANT: mandatory for trusted publishing

    steps:
    - name: Download all the dists
      uses: actions/download-artifact@v4
      with:
        name: python-package-distributions
        path: dist/
    - name: publish dist to ProdPyPI
      uses: pypa/gh-action-pypi-publish@release/v1

  run-tests:
    name: Run Tests
    needs: publish-to-prodpypi
    if: ${{ success() }}
    runs-on: ubuntu-latest
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4    

    - name: Set up Java
      uses: actions/setup-java@v4
      with:
        distribution: 'corretto'
        java-version: '17'

    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.12'    

    - name: Install Node.js
      uses: actions/setup-node@v4
      with:
        node-version: '20'

    - name: Install dependencies
      run: npm install

    - name: Set environment variables for Cypress
      run: |
        echo "POSTGRES_CONNECTION_STRING=${{ secrets.POSTGRES_CONNECTION_STRING }}" >> $GITHUB_ENV
        echo "DATABRICKS_HOSTNAME=${{ secrets.DATABRICKS_HOSTNAME }}" >> $GITHUB_ENV
        echo "DATABRICKS_HTTP_PATH=${{ secrets.DATABRICKS_HTTP_PATH }}" >> $GITHUB_ENV
        echo "DATABRICKS_ACCESS_TOKEN=${{ secrets.DATABRICKS_ACCESS_TOKEN }}" >> $GITHUB_ENV
    
    - name: Run Java version check
      run: java -version

    - name: Run Python version check
      run: python --version
    
    - name: Install Dataforge from latest release
      run: |
        pip install dataforge-core

    - name: Run Dataforge version check
      run: dataforge --version

    - name: Run interactive Dataforge configuration
      env:
        POSTGRES_CONNECTION_STRING: ${{ secrets.POSTGRES_CONNECTION_STRING }}
        DATABRICKS_HOSTNAME: ${{ secrets.DATABRICKS_HOSTNAME }}
        DATABRICKS_HTTP_PATH: ${{ secrets.DATABRICKS_HTTP_PATH }}
        DATABRICKS_ACCESS_TOKEN: ${{ secrets.DATABRICKS_ACCESS_TOKEN }}
      run: |
        config_output=$(node scripts/runInteractiveCommand.js --configure)
        echo "Dataforge configuration output: $config_output"
        if echo "$config_output" | grep -q "Databricks connection validated successfully"; then
          echo "Databricks configuration completed successfully."
        else
          echo "Databricks configuration validation failed."
          exit 1
        fi

    - name: Initialize Dataforge
      run: |
        init_output=$(dataforge --init)
        echo "Dataforge initialization output: $init_output"
        if echo "$init_output" | grep -q "Initialized project"; then
          echo "Dataforge initialized successfully."
        else
          echo "Dataforge initialization failed."
          exit 1
        fi

    - name: Run interactive Dataforge seeding
      run: node scripts/runInteractiveCommand.js --seed

    - name: Run Dataforge build
      run: |
        build_output=$(dataforge --build)
        echo "Dataforge build output: $build_output"
        if echo "$build_output" | grep -q "Import completed successfully"; then
          echo "build completed successfully."
        else
          echo "Dataforge build failed."
          exit 1
        fi

    - name: Run Dataforge process
      run: |
        process_output=$(dataforge --run)
        echo "Dataforge process output: $process_output"
        if echo "$process_output" | grep -q "Execution completed successfully"; then
          echo "run completed successfully."
        else
          echo "Dataforge process failed."
          exit 1
        fi
 
      

